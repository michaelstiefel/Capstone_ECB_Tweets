import configparser
import boto3
import json
import pandas as pd
import pickle
import nltk
nltk.download('vader_lexicon')
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Read AWS credentials and set up s3 client to access the tweets
# (Stored as json files in S3 bucket)
config = configparser.ConfigParser()
config.read("capstone_project.cfg")

AWS_ACCESS_KEY_ID =config['AWS']['AWS_ACCESS_KEY_ID']
AWS_SECRET_ACCESS_KEY = config['AWS']['AWS_SECRET_ACCESS_KEY']
S3_BUCKET = config['AWS']['S3_BUCKET_INPUT']

s3 = boto3.client("s3", aws_access_key_id=AWS_ACCESS_KEY_ID,
                         aws_secret_access_key=AWS_SECRET_ACCESS_KEY)


def list_of_files():
    """
    This function returns a list with all filenames in the provided S3 bucket
    """
    s3_resource = boto3.resource('s3')
    my_bucket = s3_resource.Bucket(S3_BUCKET)
    summaries = my_bucket.objects.all()
    files = []
    for file in summaries:
        files.append(file.key)

    return files

files = list_of_files()


def flatten_tweets(tweets_json):
    """
    This function takes a json file generated by the Twitter API.
    It flattens the tweets, only keeps the important columns and
    saves the result as a dataframe.
    Note that to make the following analysis easier, it collapses all tweet
    text columns (text of extended tweet, quoted tweet, retweet, ...) into a
    column "all_text".
    """
    tweets_list = []
    fields_to_keep = ['id', 'created_at', 'lang',
    'text', 'retweeted_status_text', 'all_text', 'quoted_status_text',
     # Aditional user information
    'user_screen_name','user_description', 'user_followers_count', 'user_friends_count',
    'user_id', 'user_verified', 'user_created_at',
     # Additional retweet information
    'retweeted_status_id', 'retweeted_status_user_id',
    'retweeted_status_user_screen_name', 'retweeted_status_user_description',
    'retweeted_status_user_followers_count', 'retweeted_status_user_friends_count',
    'retweeted_status_user_verified', 'retweeted_status_user_created_at',
    # Additional quoted status information
    'quoted_status_id', 'quoted_status_user_id',
    'quoted_status_user_screen_name', 'quoted_status_user_description',
    'quoted_status_user_followers_count', 'quoted_status_user_friends_count',
    'quoted_status_user_verified', 'quoted_status_user_created_at']

    # Iterate through each tweet
    for tweet in tweets_json:

        tweet_obj = json.loads(tweet)

        # Store user information
        tweet_obj['user_screen_name'] = tweet_obj['user']['screen_name']

        tweet_obj['user_description'] = tweet_obj['user']['description']

        tweet_obj['user_followers_count'] = tweet_obj['user']['followers_count']

        tweet_obj['user_friends_count'] = tweet_obj['user']['friends_count']

        tweet_obj['user_id'] = tweet_obj['user']['id']

        tweet_obj['user_verified'] = tweet_obj['user']['verified']

        tweet_obj['user_created_at'] = tweet_obj['user']['created_at']

        # Check if the tweet contains more than 140 characters
        if 'extended_tweet' in tweet_obj:
            # Store the extended tweet text in text
            tweet_obj['text'] = tweet_obj['extended_tweet']['full_text']
        else:
            tweet_obj['text'] = tweet_obj['text']

        if 'retweeted_status' in tweet_obj:
            # Store user and tweet information of the retweet
            tweet_obj['retweeted_status_user_screen_name'] = tweet_obj['retweeted_status']['user']['screen_name']
            tweet_obj['retweeted_status_user_description'] = tweet_obj['retweeted_status']['user']['description']
            tweet_obj['retweeted_status_user_followers_count'] = tweet_obj['retweeted_status']['user']['followers_count']
            tweet_obj['retweeted_status_user_friends_count'] = tweet_obj['retweeted_status']['user']['friends_count']
            tweet_obj['retweeted_status_user_id'] = tweet_obj['retweeted_status']['user']['id']
            tweet_obj['retweeted_status_user_verified'] = tweet_obj['retweeted_status']['user']['verified']
            tweet_obj['retweeted_status_user_created_at'] = tweet_obj['retweeted_status']['user']['created_at']
            tweet_obj['retweeted_status_id'] = tweet_obj['retweeted_status']['id']
            # Store the retweet text in 'retweeted_status-text'
            if 'extended_tweet' in tweet_obj['retweeted_status']:
                tweet_obj['retweeted_status_text'] = tweet_obj['retweeted_status']['extended_tweet']['full_text']
            else:
                tweet_obj['retweeted_status_text'] = tweet_obj['retweeted_status']['text']
        else:
            tweet_obj['retweeted_status_user_screen_name'] = None
            tweet_obj['retweeted_status_user_description'] = None
            tweet_obj['retweeted_status_user_followers_count'] = None
            tweet_obj['retweeted_status_user_friends_count'] = None
            tweet_obj['retweeted_status_user_id'] = None
            tweet_obj['retweeted_status_id'] = None
            tweet_obj['retweeted_status_user_verified'] = None
            tweet_obj['retweeted_status_user_created_at'] = None
            tweet_obj['retweeted_status_text'] = None


        if 'quoted_status' in tweet_obj:
            # Store user and tweet information of the quoted tweet
            tweet_obj['quoted_status_user_screen_name'] = tweet_obj['quoted_status']['user']['screen_name']
            tweet_obj['quoted_status_user_description'] = tweet_obj['quoted_status']['user']['description']
            tweet_obj['quoted_status_user_followers_count'] = tweet_obj['quoted_status']['user']['followers_count']
            tweet_obj['quoted_status_user_friends_count'] = tweet_obj['quoted_status']['user']['friends_count']
            tweet_obj['quoted_status_user_id'] = tweet_obj['quoted_status']['user']['id']
            tweet_obj['quoted_status_user_verified'] = tweet_obj['quoted_status']['user']['verified']
            tweet_obj['quoted_status_user_created_at'] = tweet_obj['quoted_status']['user']['created_at']
            tweet_obj['quoted_status_id'] = tweet_obj['quoted_status']['id']
            # Store the retweet text in 'retweeted_status-text'
            if 'extended_tweet' in tweet_obj['quoted_status']:
                tweet_obj['quoted_status_text'] = tweet_obj['quoted_status']['extended_tweet']['full_text']
            else:
                tweet_obj['quoted_status_text'] = tweet_obj['quoted_status']['text']

            tweet_obj['all_text'] = tweet_obj['text'] + " " + tweet_obj['quoted_status_text']
        else:
            tweet_obj['quoted_status_user_screen_name'] = None
            tweet_obj['quoted_status_user_description'] = None
            tweet_obj['quoted_status_user_followers_count'] = None
            tweet_obj['quoted_status_user_friends_count'] = None
            tweet_obj['quoted_status_user_id'] = None
            tweet_obj['quoted_status_id'] = None
            tweet_obj['quoted_status_user_verified'] = None
            tweet_obj['quoted_status_user_created_at'] = None
            tweet_obj['quoted_status_text'] = None
            tweet_obj['all_text'] = tweet_obj['text']

        tweet_obj = {key_to_keep: tweet_obj[key_to_keep] for key_to_keep in fields_to_keep }
        tweets_list.append(tweet_obj)

    return pd.DataFrame(tweets_list)

# Initialize Vader Sentiment Analyzer
sid = SentimentIntensityAnalyzer()

# Apply cleaning steps to all json files with tweets on AWS S3 Bucket
# Also compute sentiment score for all tweets
all_dfs = []
for file in files:
    print(file)
    obj = s3.get_object(Bucket = S3_BUCKET, Key = file)
    obj_body = obj['Body'].read().decode('utf-8')
    try:
        df = flatten_tweets(obj_body.splitlines())
        df['sentiment_scores'] = df['all_text'].apply(lambda tweet: sid.polarity_scores(tweet))
        df['compound']  = df['sentiment_scores'].apply(lambda score_dict: score_dict['compound'])

        # For preliminary analysis, focus only on the following variables
        df = df[['id', 'created_at', 'all_text', 'compound', 'user_id', 'user_followers_count', 'user_verified', 'lang']]
        all_dfs.append(df)
    except:
        continue

# Bring list of dataframes into a single data frame
df_tweets = pd.concat(all_dfs)

# Filter for English language
df_tweets = df_tweets[df_tweets['lang'] == 'en']

# Exclude all tweets that contain the word cricket
df_tweets[~df_tweets['all_text'].str.contains('cricket', case=False, regex=False)]
df_tweets[~df_tweets['all_text'].str.contains('bcci', case=False, regex=False)]


print(df_tweets.head())
print(df_tweets.info())

# Save the data as csv and pickle files

df_tweets.to_csv('./webapp/data/tweets_and_sentiment.csv')
with open('./webapp/data/df_tweets.pkl', 'wb') as f:
    pickle.dump(df_tweets, f)
